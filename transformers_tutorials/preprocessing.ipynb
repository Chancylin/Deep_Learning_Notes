{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ed4255735c674114a96f3c156e4d654a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_03b26bbaa9af4f6b8cbf2ff762a090e9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e4ebb028771343ce830d3d12d4cadafb",
              "IPY_MODEL_d028edc72a254beaa8ee837e3a581287",
              "IPY_MODEL_b99974ffc51c4e95b055ccc5dbccca1b"
            ]
          }
        },
        "03b26bbaa9af4f6b8cbf2ff762a090e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4ebb028771343ce830d3d12d4cadafb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c52f146391e74ad79cb19eff4dbc46e2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ae58897287d4459b66189c200e1cb75"
          }
        },
        "d028edc72a254beaa8ee837e3a581287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4666314cad284a1d94b8accfbbdd2b86",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a3569d77c73491c977bd2dc5ee48b67"
          }
        },
        "b99974ffc51c4e95b055ccc5dbccca1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_28aa01e97db44d05a25e83c9ec679c99",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 603B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b4257caf6c047b5b0602a3a3be28cfe"
          }
        },
        "c52f146391e74ad79cb19eff4dbc46e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ae58897287d4459b66189c200e1cb75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4666314cad284a1d94b8accfbbdd2b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a3569d77c73491c977bd2dc5ee48b67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28aa01e97db44d05a25e83c9ec679c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b4257caf6c047b5b0602a3a3be28cfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77e0078629de490fbb757cb54a6a6244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e9069f8a6ee544d39fd89d9f458ce7b4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_372746df4c7549e99a3fd2b9596f8237",
              "IPY_MODEL_23a5bdcc3b364a089653e67107df6235",
              "IPY_MODEL_719116684c304a768ea2670cefee629b"
            ]
          }
        },
        "e9069f8a6ee544d39fd89d9f458ce7b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "372746df4c7549e99a3fd2b9596f8237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7c314e7e91cf488aacd21fd8db02d1dd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0177c017a084d51b9462c96d1b2f0de"
          }
        },
        "23a5bdcc3b364a089653e67107df6235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7b7b6da8160f4d87801b21fd8ee78db8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_98ec5f0102ed48c391b71fb74b5b8e36"
          }
        },
        "719116684c304a768ea2670cefee629b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c2a3c6977f0f49bcad4a28b0d7c34726",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 10.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f856f07a022a4a3d97505dc5b2667ed0"
          }
        },
        "7c314e7e91cf488aacd21fd8db02d1dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0177c017a084d51b9462c96d1b2f0de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b7b6da8160f4d87801b21fd8ee78db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "98ec5f0102ed48c391b71fb74b5b8e36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2a3c6977f0f49bcad4a28b0d7c34726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f856f07a022a4a3d97505dc5b2667ed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6da19ca406e34fbd966df2f3383c8cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_541fa139da1145258b66877be1c5aff2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c415654d9a4241acb0cd47bec7fa6225",
              "IPY_MODEL_0316c3d38bfd47548717ad8252350560",
              "IPY_MODEL_fa610fa3637d4e068b6be023eb07e92a"
            ]
          }
        },
        "541fa139da1145258b66877be1c5aff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c415654d9a4241acb0cd47bec7fa6225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_352b04f44cca4c61834c3aebbe4d5cee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a633c3e1a12429dad80960e000c7141"
          }
        },
        "0316c3d38bfd47548717ad8252350560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_31ca9b3d60d34f32a42a907f9e8bb2dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_450c26d9998440e68beba688c16f3424"
          }
        },
        "fa610fa3637d4e068b6be023eb07e92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bc272ee6cb1244c08d076adf9a02936f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 701kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_217affa7614947178e44b37f03d35c52"
          }
        },
        "352b04f44cca4c61834c3aebbe4d5cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a633c3e1a12429dad80960e000c7141": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31ca9b3d60d34f32a42a907f9e8bb2dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "450c26d9998440e68beba688c16f3424": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc272ee6cb1244c08d076adf9a02936f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "217affa7614947178e44b37f03d35c52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6f74b0c432a463ea7716fe363b3feaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c332993c3ab24d63b647600df1ebe6df",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8290738d449348af81efb545d797795d",
              "IPY_MODEL_4f3a92210e63480aa8b5e66998bc4b14",
              "IPY_MODEL_49d653dc9fd749698f784f8f84855e51"
            ]
          }
        },
        "c332993c3ab24d63b647600df1ebe6df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8290738d449348af81efb545d797795d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_049f54317ab049d1988fbddddb34cdaa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03b9e885ed6e458b8fc5dd7ca3d916ee"
          }
        },
        "4f3a92210e63480aa8b5e66998bc4b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3548ed55bad5462a93b3d52c3b2e4a19",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1fb84a09d56e493bbde2d8812e172120"
          }
        },
        "49d653dc9fd749698f784f8f84855e51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_940e294a38894403a6bac26710803a79",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436k/436k [00:00&lt;00:00, 746kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_366c05eacebd4450a167f85e25ac290d"
          }
        },
        "049f54317ab049d1988fbddddb34cdaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03b9e885ed6e458b8fc5dd7ca3d916ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3548ed55bad5462a93b3d52c3b2e4a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1fb84a09d56e493bbde2d8812e172120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "940e294a38894403a6bac26710803a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "366c05eacebd4450a167f85e25ac290d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chancylin/Deep_Learning_Notes/blob/master/transformers_tutorials/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIlDbkkuqiZ0",
        "outputId": "a85c3a8e-fef7-447f-f12c-3976ea9c3719"
      },
      "source": [
        "# Transformers installation\n",
        "! pip install transformers datasets\n",
        "# To install from source instead of the last release, comment the command above and uncomment the following one.\n",
        "# ! pip install git+https://github.com/huggingface/transformers.git\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.10.3-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 7.5 MB/s \n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-1.12.1-py3-none-any.whl (270 kB)\n",
            "\u001b[K     |████████████████████████████████| 270 kB 41.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 60.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 62.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 52.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 47.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 60.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.9.0-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 61.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 62.6 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 64.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: multidict, yarl, async-timeout, fsspec, aiohttp, xxhash, tokenizers, sacremoses, pyyaml, huggingface-hub, transformers, datasets\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 datasets-1.12.1 fsspec-2021.9.0 huggingface-hub-0.0.17 multidict-5.1.0 pyyaml-5.4.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.10.3 xxhash-2.0.2 yarl-1.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUwSVEk_qiZ3"
      },
      "source": [
        "# Preprocessing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH5zpgjrqiZ4"
      },
      "source": [
        "In this tutorial, we'll explore how to preprocess your data using 🤗 Transformers. The main tool for this is what we\n",
        "call a [tokenizer](https://huggingface.co/transformers/main_classes/tokenizer.html). You can build one using the tokenizer class associated to the model\n",
        "you would like to use, or directly with the `AutoTokenizer` class.\n",
        "\n",
        "As we saw in the [quick tour](https://huggingface.co/transformers/quicktour.html), the tokenizer will first split a given text in words (or part of\n",
        "words, punctuation symbols, etc.) usually called *tokens*. Then it will convert those *tokens* into numbers, to be able\n",
        "to build a tensor out of them and feed them to the model. It will also add any additional inputs the model might expect\n",
        "to work properly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEU0aT8lqiZ5"
      },
      "source": [
        "> **NOTE:** If you plan on using a pretrained model, it's important to use the associated pretrained tokenizer: it will split\n",
        "> the text you give it in tokens the same way for the pretraining corpus, and it will use the same correspondence\n",
        "> token to index (that we usually call a *vocab*) as during pretraining."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqwFX6-5qiZ6"
      },
      "source": [
        "To automatically download the vocab used during pretraining or fine-tuning a given model, you can use the\n",
        "`AutoTokenizer.from_pretrained` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "ed4255735c674114a96f3c156e4d654a",
            "03b26bbaa9af4f6b8cbf2ff762a090e9",
            "e4ebb028771343ce830d3d12d4cadafb",
            "d028edc72a254beaa8ee837e3a581287",
            "b99974ffc51c4e95b055ccc5dbccca1b",
            "c52f146391e74ad79cb19eff4dbc46e2",
            "8ae58897287d4459b66189c200e1cb75",
            "4666314cad284a1d94b8accfbbdd2b86",
            "7a3569d77c73491c977bd2dc5ee48b67",
            "28aa01e97db44d05a25e83c9ec679c99",
            "6b4257caf6c047b5b0602a3a3be28cfe",
            "77e0078629de490fbb757cb54a6a6244",
            "e9069f8a6ee544d39fd89d9f458ce7b4",
            "372746df4c7549e99a3fd2b9596f8237",
            "23a5bdcc3b364a089653e67107df6235",
            "719116684c304a768ea2670cefee629b",
            "7c314e7e91cf488aacd21fd8db02d1dd",
            "b0177c017a084d51b9462c96d1b2f0de",
            "7b7b6da8160f4d87801b21fd8ee78db8",
            "98ec5f0102ed48c391b71fb74b5b8e36",
            "c2a3c6977f0f49bcad4a28b0d7c34726",
            "f856f07a022a4a3d97505dc5b2667ed0",
            "6da19ca406e34fbd966df2f3383c8cf8",
            "541fa139da1145258b66877be1c5aff2",
            "c415654d9a4241acb0cd47bec7fa6225",
            "0316c3d38bfd47548717ad8252350560",
            "fa610fa3637d4e068b6be023eb07e92a",
            "352b04f44cca4c61834c3aebbe4d5cee",
            "8a633c3e1a12429dad80960e000c7141",
            "31ca9b3d60d34f32a42a907f9e8bb2dc",
            "450c26d9998440e68beba688c16f3424",
            "bc272ee6cb1244c08d076adf9a02936f",
            "217affa7614947178e44b37f03d35c52",
            "a6f74b0c432a463ea7716fe363b3feaa",
            "c332993c3ab24d63b647600df1ebe6df",
            "8290738d449348af81efb545d797795d",
            "4f3a92210e63480aa8b5e66998bc4b14",
            "49d653dc9fd749698f784f8f84855e51",
            "049f54317ab049d1988fbddddb34cdaa",
            "03b9e885ed6e458b8fc5dd7ca3d916ee",
            "3548ed55bad5462a93b3d52c3b2e4a19",
            "1fb84a09d56e493bbde2d8812e172120",
            "940e294a38894403a6bac26710803a79",
            "366c05eacebd4450a167f85e25ac290d"
          ]
        },
        "id": "f3WVR9V8qiZ6",
        "outputId": "1aec5541-d2e1-4f4e-d128-932cb2ebc96d"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed4255735c674114a96f3c156e4d654a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77e0078629de490fbb757cb54a6a6244",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6da19ca406e34fbd966df2f3383c8cf8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6f74b0c432a463ea7716fe363b3feaa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH3rb1BSqiZ6"
      },
      "source": [
        "## Base use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2JHGL8RqiZ7"
      },
      "source": [
        "> **RAW HTML:** <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Yffk5aydLzg\" title=\"YouTube video player\"\n",
        "> frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope;\n",
        "> picture-in-picture\" allowfullscreen></iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHME_ocYqiZ7"
      },
      "source": [
        "A `PreTrainedTokenizer` has many methods, but the only one you need to remember for preprocessing\n",
        "is its `__call__`: you just need to feed your sentence to your tokenizer object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Skw3SXnHqiZ7",
        "outputId": "e9dc9b90-7a5a-4064-ad3f-b19be57169ac"
      },
      "source": [
        "encoded_input = tokenizer(\"Hello, I'm a single sentence!\")\n",
        "print(encoded_input)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 8667, 117, 146, 112, 182, 170, 1423, 5650, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnoHHf1Mr5qv",
        "outputId": "64089e20-69f9-4541-fc48-6f140a2a6cef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoded_input.keys()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upd-2v-OtONF",
        "outputId": "4779a13e-e343-42f9-b234-13bd1163037b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoded_input.word_ids()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, None]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNJQbqotut8F",
        "outputId": "dfdcad95-7b46-4ab8-b9e6-e6b51f50feee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "input_sent = \"Hello, I'm a single sentence!\"\n",
        "charSpan = encoded_input.word_to_chars(0)\n",
        "input_sent[charSpan.start: charSpan.end]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hello'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEQWLOfutbJn",
        "outputId": "05a01ec9-fdcc-45fc-fa1b-d71ebcd99ee4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "input_sent = \"Hello, I'm a single sentence!\"\n",
        "\n",
        "# Build your desired mapping\n",
        "desired_output = []\n",
        "for word_id in encoded_input.word_ids():\n",
        "    if word_id is not None:\n",
        "        charSpan = encoded_input.word_to_chars(word_id)\n",
        "        print(input_sent[charSpan.start: charSpan.end])\n",
        "        start, end = encoded_input.word_to_tokens(word_id)\n",
        "        desired_output.append((start, end))\n",
        "desired_output\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n",
            ",\n",
            "I\n",
            "'\n",
            "m\n",
            "a\n",
            "single\n",
            "sentence\n",
            "!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS9q5Jc-qiZ8"
      },
      "source": [
        "This returns a dictionary string to list of ints. The [input_ids](https://huggingface.co/transformers/glossary.html#input-ids) are the indices\n",
        "corresponding to each token in our sentence. We will see below what the [attention_mask](https://huggingface.co/transformers/glossary.html#attention-mask) is used for and in [the next section](#sentence-pairs) the goal of\n",
        "[token_type_ids](https://huggingface.co/transformers/glossary.html#token-type-ids).\n",
        "\n",
        "The tokenizer can decode a list of token ids in a proper sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odhW2n46qiZ9",
        "outputId": "b5bfea23-06ea-430d-dd49-58756b1c5735"
      },
      "source": [
        "tokenizer.decode(encoded_input[\"input_ids\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"[CLS] Hello, I'm a single sentence! [SEP]\""
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q0nsmpwyZtz",
        "outputId": "cca3599b-676a-4461-92db-09c9e5ad9750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#clin, actually the encode and decode can be 100% reversed.\n",
        "tokenizer.decode(encoded_input[\"input_ids\"], skip_special_tokens=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Hello, I'm a single sentence!\""
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aka3y2vwqiZ9"
      },
      "source": [
        "As you can see, the tokenizer automatically added some special tokens that the model expects. <font color='red'>Not all models need\n",
        "special tokens</font>; for instance, if we had used *gpt2-medium* instead of *bert-base-cased* to create our tokenizer, we\n",
        "would have seen the same sentence as the original one here. You can disable this behavior (which is only advised if you\n",
        "have added those special tokens yourself) by passing `add_special_tokens=False`.\n",
        "\n",
        "If you have several sentences you want to process, you can do this efficiently by sending them as a list to the\n",
        "tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CHX1jCeqiZ-",
        "outputId": "9c24143a-0861-407f-ac91-19e475b96b60"
      },
      "source": [
        "batch_sentences = [\"Hello I'm a single sentence\",\n",
        "                   \"And another sentence\",\n",
        "                   \"And the very very last one\"]\n",
        "encoded_inputs = tokenizer(batch_sentences)\n",
        "print(encoded_inputs)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 8667, 146, 112, 182, 170, 1423, 5650, 102], [101, 1262, 1330, 5650, 102], [101, 1262, 1103, 1304, 1304, 1314, 1141, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwfYh4xKqiZ-"
      },
      "source": [
        "We get back a dictionary once again, this time with values being lists of lists of ints.\n",
        "\n",
        "If the purpose of sending several sentences at a time to the tokenizer is to build a batch to feed the model, you will\n",
        "probably want:\n",
        "\n",
        "- To pad each sentence to the maximum length there is in your batch.\n",
        "- To truncate each sentence to the maximum length the model can accept (if applicable).\n",
        "- To return tensors.\n",
        "\n",
        "You can do all of this by using the following options when feeding your list of sentences to the tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2ZkKr-pqiZ-",
        "outputId": "0c6d1059-05ed-4e18-854a-ba2de6b500a0"
      },
      "source": [
        "## PYTORCH CODE\n",
        "batch = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "print(batch)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 8667,  146,  112,  182,  170, 1423, 5650,  102],\n",
            "        [ 101, 1262, 1330, 5650,  102,    0,    0,    0,    0],\n",
            "        [ 101, 1262, 1103, 1304, 1304, 1314, 1141,  102,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW_IB7KBqiZ_",
        "outputId": "57d2e6c0-ce04-49a8-fc9e-f00d96337060"
      },
      "source": [
        "## TENSORFLOW CODE\n",
        "batch = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "print(batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tf.Tensor([[ 101, 8667,  146,  112,  182,  170, 1423, 5650,  102],\n",
              "                      [ 101, 1262, 1330, 5650,  102,    0,    0,    0,    0],\n",
              "                      [ 101, 1262, 1103, 1304, 1304, 1314, 1141,  102,    0]]),\n",
              " 'token_type_ids': tf.Tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "                           [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "                           [0, 0, 0, 0, 0, 0, 0, 0, 0]]), \n",
              " 'attention_mask': tf.Tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "                           [1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
              "                           [1, 1, 1, 1, 1, 1, 1, 1, 0]])}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTlJ5V0xqiZ_"
      },
      "source": [
        "It returns a dictionary with string keys and tensor values. We can now see what the [attention_mask](https://huggingface.co/transformers/glossary.html#attention-mask) is all about: it points out which tokens the model should pay attention to and which\n",
        "ones it should not (because they represent padding in this case).\n",
        "\n",
        "\n",
        "Note that if your model does not have a maximum length associated to it, the command above will throw a warning. You\n",
        "can safely ignore it. You can also pass `verbose=False` to stop the tokenizer from throwing those kinds of warnings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "196y_JgUqiZ_"
      },
      "source": [
        "<a id='sentence-pairs'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX8c8Y-_qiaA"
      },
      "source": [
        "## Preprocessing pairs of sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pop9qXoSqiaA"
      },
      "source": [
        "> **RAW HTML:** <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/0u3ioSwev3s\" title=\"YouTube video player\"\n",
        "> frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope;\n",
        "> picture-in-picture\" allowfullscreen></iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqysox7mqiaA"
      },
      "source": [
        "Sometimes you need to feed a pair of sentences to your model. For instance, if you want to classify if two sentences in\n",
        "a pair are similar, or for question-answering models, which take a context and a question. For BERT models, the input\n",
        "is then represented like this: `[CLS] Sequence A [SEP] Sequence B [SEP]`\n",
        "\n",
        "You can encode a pair of sentences in the format expected by your model by supplying the two sentences as two arguments\n",
        "(not a list since a list of two sentences will be interpreted as a batch of two single sentences, as we saw before).\n",
        "This will once again return a dict string to list of ints:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKOAwYUJqiaA",
        "outputId": "cc289fb0-821f-4b6a-eef3-6ae06b8450dc"
      },
      "source": [
        "encoded_input = tokenizer(\"How old are you?\", \"I'm 6 years old\")\n",
        "print(encoded_input)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 1731, 1385, 1132, 1128, 136, 102, 146, 112, 182, 127, 1201, 1385, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4nS718XqiaA"
      },
      "source": [
        "This shows us what the [token_type_ids](https://huggingface.co/transformers/glossary.html#token-type-ids) are for: they indicate to the model which part\n",
        "of the inputs correspond to the first sentence and which part corresponds to the second sentence. Note that\n",
        "*token_type_ids* are not required or handled by all models. By default, a tokenizer will only return the inputs that\n",
        "its associated model expects. You can force the return (or the non-return) of any of those special arguments by using\n",
        "`return_input_ids` or `return_token_type_ids`.\n",
        "\n",
        "If we decode the token ids we obtained, we will see that the special tokens have been properly added."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ya46HRCUqiaB",
        "outputId": "47ad71e4-e428-41e3-e3a7-e410519bdbcd"
      },
      "source": [
        "tokenizer.decode(encoded_input[\"input_ids\"])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"[CLS] How old are you? [SEP] I'm 6 years old [SEP]\""
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot7SBDk3qiaB"
      },
      "source": [
        "If you have a list of pairs of sequences you want to process, you should feed them as two lists to your tokenizer: the\n",
        "list of first sentences and the list of second sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5MZB0CQqiaB",
        "outputId": "75a7a713-40b0-441a-ad6c-be4c874c2993"
      },
      "source": [
        "batch_sentences = [\"Hello I'm a single sentence\",\n",
        "                   \"And another sentence\",\n",
        "                   \"And the very very last one\"]\n",
        "batch_of_second_sentences = [\"I'm a sentence that goes with the first sentence\",\n",
        "                             \"And I should be encoded with the second sentence\",\n",
        "                             \"And I go with the very last one\"]\n",
        "encoded_inputs = tokenizer(batch_sentences, batch_of_second_sentences)\n",
        "print(encoded_inputs)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 8667, 146, 112, 182, 170, 1423, 5650, 102, 146, 112, 182, 170, 5650, 1115, 2947, 1114, 1103, 1148, 5650, 102], [101, 1262, 1330, 5650, 102, 1262, 146, 1431, 1129, 12544, 1114, 1103, 1248, 5650, 102], [101, 1262, 1103, 1304, 1304, 1314, 1141, 102, 1262, 146, 1301, 1114, 1103, 1304, 1314, 1141, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nu6u_8t1gYO",
        "outputId": "2ebb6256-97af-4269-d993-ebed4f2ffe47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoded_inputs"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 8667, 146, 112, 182, 170, 1423, 5650, 102, 146, 112, 182, 170, 5650, 1115, 2947, 1114, 1103, 1148, 5650, 102], [101, 1262, 1330, 5650, 102, 1262, 146, 1431, 1129, 12544, 1114, 1103, 1248, 5650, 102], [101, 1262, 1103, 1304, 1304, 1314, 1141, 102, 1262, 146, 1301, 1114, 1103, 1304, 1314, 1141, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjV5iceFqiaB"
      },
      "source": [
        "As we can see, it returns a dictionary where each value is a list of lists of ints.\n",
        "\n",
        "To double-check what is fed to the model, we can decode each list in *input_ids* one by one:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_KCWeOiqiaC",
        "outputId": "bc8ff995-f1c0-42b5-a080-4cb5d26ff99a"
      },
      "source": [
        "for ids in encoded_inputs[\"input_ids\"]:\n",
        "    print(tokenizer.decode(ids))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] Hello I'm a single sentence [SEP] I'm a sentence that goes with the first sentence [SEP]\n",
            "[CLS] And another sentence [SEP] And I should be encoded with the second sentence [SEP]\n",
            "[CLS] And the very very last one [SEP] And I go with the very last one [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTNvyKmCqiaC"
      },
      "source": [
        "Once again, you can automatically pad your inputs to the maximum sentence length in the batch, truncate to the maximum\n",
        "length the model can accept and return tensors directly with the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-dhIHNWqiaC"
      },
      "source": [
        "## PYTORCH CODE\n",
        "batch = tokenizer(batch_sentences, batch_of_second_sentences, padding=True, truncation=True, return_tensors=\"pt\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGMhZ_7eqiaC"
      },
      "source": [
        "## TENSORFLOW CODE\n",
        "batch = tokenizer(batch_sentences, batch_of_second_sentences, padding=True, truncation=True, return_tensors=\"tf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqmt2STiqiaC"
      },
      "source": [
        "## Everything you always wanted to know about padding and truncation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQtpeJ6kqiaC"
      },
      "source": [
        "We have seen the commands that will work for most cases (pad your batch to the length of the maximum sentence and\n",
        "truncate to the maximum length the mode can accept). However, the API supports more strategies if you need them. The\n",
        "three arguments you need to know for this are `padding`, `truncation` and `max_length`.\n",
        "\n",
        "- `padding` controls the padding. It can be a boolean or a string which should be:\n",
        "\n",
        "    - `True` or `'longest'` to pad to the longest sequence in the batch (doing no padding if you only provide\n",
        "      a single sequence).\n",
        "    - `'max_length'` to pad to a length specified by the `max_length` argument or the maximum length accepted\n",
        "      by the model if no `max_length` is provided (`max_length=None`). If you only provide a single sequence,\n",
        "      padding will still be applied to it.\n",
        "    - `False` or `'do_not_pad'` to not pad the sequences. As we have seen before, this is the default\n",
        "      behavior.\n",
        "\n",
        "- `truncation` controls the truncation. It can be a boolean or a string which should be:\n",
        "\n",
        "    - `True` or `'only_first'` truncate to a maximum length specified by the `max_length` argument or\n",
        "      the maximum length accepted by the model if no `max_length` is provided (`max_length=None`). This will\n",
        "      only truncate the first sentence of a pair if a pair of sequence (or a batch of pairs of sequences) is provided.\n",
        "    - `'only_second'` truncate to a maximum length specified by the `max_length` argument or the maximum\n",
        "      length accepted by the model if no `max_length` is provided (`max_length=None`). This will only truncate\n",
        "      the second sentence of a pair if a pair of sequence (or a batch of pairs of sequences) is provided.\n",
        "    - `'longest_first'` truncate to a maximum length specified by the `max_length` argument or the maximum\n",
        "      length accepted by the model if no `max_length` is provided (`max_length=None`). This will truncate token\n",
        "      by token, removing a token from the longest sequence in the pair until the proper length is reached.\n",
        "    - `False` or `'do_not_truncate'` to not truncate the sequences. As we have seen before, this is the\n",
        "      default behavior.\n",
        "\n",
        "- `max_length` to control the length of the padding/truncation. It can be an integer or `None`, in which case\n",
        "  it will default to the maximum length the model can accept. If the model has no specific maximum input length,\n",
        "  truncation/padding to `max_length` is deactivated.\n",
        "\n",
        "Here is a table summarizing the recommend way to setup padding and truncation. If you use pair of inputs sequence in\n",
        "any of the following examples, you can replace `truncation=True` by a `STRATEGY` selected in\n",
        "`['only_first', 'only_second', 'longest_first']`, i.e. `truncation='only_second'` or `truncation=\n",
        "'longest_first'` to control how both sequence in the pair are truncated as detailed before.\n",
        "\n",
        "| Truncation                           | Padding                           | Instruction                                                                                 |\n",
        "|--------------------------------------|-----------------------------------|---------------------------------------------------------------------------------------------|\n",
        "| no truncation                        | no padding                        | `tokenizer(batch_sentences)`                                                           |\n",
        "|                                      | padding to max sequence in batch  | `tokenizer(batch_sentences, padding=True)` or                                          |\n",
        "|                                      |                                   | `tokenizer(batch_sentences, padding='longest')`                                        |\n",
        "|                                      | padding to max model input length | `tokenizer(batch_sentences, padding='max_length')`                                     |\n",
        "|                                      | padding to specific length        | `tokenizer(batch_sentences, padding='max_length', max_length=42)`                      |\n",
        "| truncation to max model input length | no padding                        | `tokenizer(batch_sentences, truncation=True)` or                                       |\n",
        "|                                      |                                   | `tokenizer(batch_sentences, truncation=STRATEGY)`                                      |\n",
        "|                                      | padding to max sequence in batch  | `tokenizer(batch_sentences, padding=True, truncation=True)` or                         |\n",
        "|                                      |                                   | `tokenizer(batch_sentences, padding=True, truncation=STRATEGY)`                        |\n",
        "|                                      | padding to max model input length | `tokenizer(batch_sentences, padding='max_length', truncation=True)` or                 |\n",
        "|                                      |                                   | `tokenizer(batch_sentences, padding='max_length', truncation=STRATEGY)`                |\n",
        "|                                      | padding to specific length        | Not possible                                                                                |\n",
        "| truncation to specific length        | no padding                        | `tokenizer(batch_sentences, truncation=True, max_length=42)` or                        |\n",
        "|                                      |                                   | `tokenizer(batch_sentences, truncation=STRATEGY, max_length=42)`                       |\n",
        "|                                      | padding to max sequence in batch  | `tokenizer(batch_sentences, padding=True, truncation=True, max_length=42)` or          |\n",
        "|                                      |                                   | `tokenizer(batch_sentences, padding=True, truncation=STRATEGY, max_length=42)`         |\n",
        "|                                      | padding to max model input length | Not possible                                                                                |\n",
        "|                                      | padding to specific length        | `tokenizer(batch_sentences, padding='max_length', truncation=True, max_length=42)` or  |\n",
        "|                                      |                                   | `tokenizer(batch_sentences, padding='max_length', truncation=STRATEGY, max_length=42)` |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKWJUzuPqiaE"
      },
      "source": [
        "## Pre-tokenized inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVeiYexzqiaG"
      },
      "source": [
        "The tokenizer also accept pre-tokenized inputs. This is particularly useful when you want to compute labels and extract\n",
        "predictions in [named entity recognition (NER)](https://en.wikipedia.org/wiki/Named-entity_recognition) or\n",
        "[part-of-speech tagging (POS tagging)](https://en.wikipedia.org/wiki/Part-of-speech_tagging)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHj_ud9TqiaG"
      },
      "source": [
        "> **WARNING:** Pre-tokenized does not mean your inputs are already tokenized (you wouldn't need to pass them through the tokenizer\n",
        "> if that was the case) but just split into words (which is often the first step in subword tokenization algorithms\n",
        "> like BPE)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fwtj8ucqiaG"
      },
      "source": [
        "If you want to use pre-tokenized inputs, just set `is_split_into_words=True` when passing your inputs to the\n",
        "tokenizer. For instance, we have:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFNLzgw-qiaH",
        "outputId": "a6f976e0-b356-4594-dd0d-d7e696d0947b"
      },
      "source": [
        "encoded_input = tokenizer([\"Hello\", \"I'm\", \"a\", \"single\", \"sentence\"], is_split_into_words=True)\n",
        "print(encoded_input)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 8667, 146, 112, 182, 170, 1423, 5650, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV42S0ehqiaH"
      },
      "source": [
        "Note that the tokenizer still adds the ids of special tokens (if applicable) unless you pass\n",
        "`add_special_tokens=False`.\n",
        "\n",
        "This works exactly as before for batch of sentences or batch of pairs of sentences. You can encode a batch of sentences\n",
        "like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z161I1nqiaH"
      },
      "source": [
        "batch_sentences = [[\"Hello\", \"I'm\", \"a\", \"single\", \"sentence\"],\n",
        "                   [\"And\", \"another\", \"sentence\"],\n",
        "                   [\"And\", \"the\", \"very\", \"very\", \"last\", \"one\"]]\n",
        "encoded_inputs = tokenizer(batch_sentences, is_split_into_words=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBDy0rXk6LBl",
        "outputId": "ea7d3c55-6ba9-478e-a45c-28953c429d3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoded_inputs['input_ids'][0]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 8667, 146, 112, 182, 170, 1423, 5650, 102]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wborUvj4RJT",
        "outputId": "02776fbc-13dc-4559-863c-07b54d0a4533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# tokenizer.decode(encoded_inputs[0].ids)\n",
        "tokenizer.decode(encoded_inputs['input_ids'][0])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"[CLS] Hello I'm a single sentence [SEP]\""
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4h7mRof8RFR",
        "outputId": "24c2bd47-95a8-4de7-efcc-55726350d39c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoded_inputs.tokens(0)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]', 'Hello', 'I', \"'\", 'm', 'a', 'single', 'sentence', '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN6j8cRv3lLu",
        "outputId": "94f23342-c75e-4f0b-81a6-c1cfa5dc2f6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(encoded_inputs.token_to_word(0, 2))  # 2 is the token index in encoded_inputs.tokens(0)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx1TcxIS-d-O",
        "outputId": "1c82dc69-1b5a-4b46-97fe-1f5567aee08e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(encoded_inputs.token_to_word(0, 0))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXR9dxBM9z1_",
        "outputId": "5e23898d-5596-4f31-aea8-51dc40e7ddaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoded_inputs.token_to_chars(0, 2)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharSpan(start=0, end=1)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlrjeGlm45DH",
        "outputId": "dffe611e-d00f-4832-b460-95d3e8e73f8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoded_inputs[0].word_ids"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, 0, 1, 1, 1, 2, 3, 4, None]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8mRXlYk3wyS",
        "outputId": "ddda1ff1-90c7-4bd3-a144-73394e79588d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# clin: will it be the same\n",
        "input_sent = [\"Hello\", \"I'm\", \"a\", \"single\", \"sentence\"]\n",
        "# Build your desired mapping\n",
        "batch_id = 0\n",
        "# desired_output = []\n",
        "for id_token, token_created in enumerate(encoded_inputs.tokens(batch_id)):\n",
        "    word_id = encoded_inputs.token_to_word(batch_id, id_token)\n",
        "    if word_id is not None:\n",
        "        currentWord = input_sent[word_id]\n",
        "\n",
        "        charSpan = encoded_inputs.token_to_chars(batch_id, id_token)\n",
        "        print(currentWord[charSpan[0]: charSpan[1]])\n",
        "\n",
        "        start, end = encoded_inputs[0].word_to_tokens(word_id)\n",
        "\n",
        "        # desired_output.append((start, end))\n",
        "# desired_output"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n",
            "I\n",
            "'\n",
            "m\n",
            "a\n",
            "single\n",
            "sentence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgIderHWqiaH"
      },
      "source": [
        "or a batch of pair sentences like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYuwkfKJqiaH"
      },
      "source": [
        "batch_of_second_sentences = [[\"I'm\", \"a\", \"sentence\", \"that\", \"goes\", \"with\", \"the\", \"first\", \"sentence\"],\n",
        "                             [\"And\", \"I\", \"should\", \"be\", \"encoded\", \"with\", \"the\", \"second\", \"sentence\"],\n",
        "                             [\"And\", \"I\", \"go\", \"with\", \"the\", \"very\", \"last\", \"one\"]]\n",
        "encoded_inputs = tokenizer(batch_sentences, batch_of_second_sentences, is_split_into_words=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbFnQYrTqiaI"
      },
      "source": [
        "And you can add padding, truncation as well as directly return tensors like before:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWVK-Y35qiaI"
      },
      "source": [
        "## PYTORCH CODE\n",
        "batch = tokenizer(batch_sentences,\n",
        "                  batch_of_second_sentences,\n",
        "                  is_split_into_words=True,\n",
        "                  padding=True,\n",
        "                  truncation=True,\n",
        "                  return_tensors=\"pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ckslNwJqiaI"
      },
      "source": [
        "## TENSORFLOW CODE\n",
        "batch = tokenizer(batch_sentences,\n",
        "                  batch_of_second_sentences,\n",
        "                  is_split_into_words=True,\n",
        "                  padding=True,\n",
        "                  truncation=True,\n",
        "                  return_tensors=\"tf\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}